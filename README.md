# ğŸ™ï¸ CodeWhisper

> **Whisper your ideas, watch them become code.** An AI-powered voice coding assistant that transforms natural language into executable code, making development faster, hands-free, and more accessible.

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![LangGraph](https://img.shields.io/badge/LangGraph-Enabled-green.svg)](https://github.com/langchain-ai/langgraph)
[![MongoDB](https://img.shields.io/badge/MongoDB-Persistence-brightgreen.svg)](https://www.mongodb.com/)
[![AI](https://img.shields.io/badge/AI-Gemini%202.0-orange.svg)](https://deepmind.google/technologies/gemini/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

## ğŸŒŸ Why CodeWhisper?

CodeWhisper isn't just another coding toolâ€”it's your intelligent pair programmer that listens, understands, and executes. Whether you're prototyping at lightning speed, coding with accessibility needs, or simply want a hands-free development experience, CodeWhisper makes it effortless.

### ğŸ’¡ The Problem We Solve

- âŒ¨ï¸ **Tired of typing?** Code fatigue is real. Give your fingers a rest.
- â™¿ **Accessibility matters**: Empowering developers with mobility challenges or RSI.
- ğŸš€ **Speed is everything**: Think it, say it, build itâ€”no context switching.
- ğŸ§  **Context is king**: Never lose your train of thought while searching docs or files.
- ğŸ¯ **Focus on logic**: Describe what you want, not how to type it.

---

## âœ¨ Powerful Features

### ğŸ¤ **Dual Input Modes**
Switch seamlessly between voice commands and text input. Perfect for when you're heads-down coding or presenting.

### ğŸ§  **Persistent Memory with MongoDB**
Your conversations aren't lost. Pick up exactly where you left off, maintaining full context across sessions.

### ğŸ”§ **Smart Tool Ecosystem**
- **Execute Shell Commands**: Run any terminal command with safety confirmations
- **Intelligent File Search**: Find code patterns across your entire project instantly
- **GitHub Integration**: Commit and push with a simple voice command
- **Live Process Monitoring**: Track system resources and running processes
- **Python Documentation**: Instant access to module docs without leaving your flow
- **Codebase Indexing**: RAG-powered understanding of your entire project

### ğŸ¤– **AI-Powered by Gemini 2.0**
Leverages Google's latest Gemini 2.0 Flash for lightning-fast natural language understanding and code generation.

### ğŸ›¡ï¸ **Safety First Design**
Destructive operations require confirmation. Your codebase stays protected while you explore.

### ğŸ“š **RAG-Enhanced Intelligence**
CodeWhisper indexes your codebase, understands relationships, and provides context-aware suggestions based on YOUR code style.

---

## ğŸ¯ Perfect For

| Use Case | How CodeWhisper Helps |
|----------|----------------------|
| ğŸƒ **Rapid Prototyping** | Scaffold entire projects with conversational commands |
| â™¿ **Accessibility** | Code without keyboardâ€”voice is your interface |
| ğŸ¥ **Live Coding/Demos** | Present and code simultaneously without switching focus |
| ğŸ“– **Learning to Code** | Describe what you want and learn from AI-generated solutions |
| ğŸ” **Code Exploration** | Navigate large codebases through natural language queries |
| âš¡ **Productivity Boost** | Reduce context switching with hands-free documentation lookup |
| ğŸ¤ **Pair Programming** | Your AI co-pilot that never gets tired |

---

## ğŸš€ Quick Start

### Prerequisites

```bash
âœ… Python 3.8 or higher
âœ… MongoDB instance (local or remote)
âœ… Google API credentials (Gemini)
âœ… Microphone (for voice mode)
```

### Installation

```bash
# 1. Clone the repository
git clone https://github.com/Uhimanshu9/CodeWhisper.git
cd CodeWhisper

# 2. Install dependencies
pip install -r voice_coding_agent/requirement.txt

# 3. Start MongoDB (using Docker)
docker-compose up -d

# 4. Configure environment
cd voice_coding_agent
cp .env.example .env
# Edit .env with your credentials
```

### Configuration

Create `.env` file:
```env
MONGODB_URI=mongodb://admin:admin@localhost:27017
GOOGLE_API_KEY=your_google_api_key_here
```

### Run CodeWhisper

```bash
cd voice_coding_agent
python audio_test.py
```

**Switch to Voice Mode**: Edit `audio_test.py` and uncomment `voice_input()`

---

## ğŸ® Usage Examples

### ğŸ¤ Voice Commands

```
ğŸ—£ï¸ "Create a FastAPI endpoint for user registration with email validation"

ğŸ—£ï¸ "Search for all TODO comments in Python files"

ğŸ—£ï¸ "Show me the documentation for the requests library"

ğŸ—£ï¸ "Push my changes to GitHub with message 'Added authentication'"

ğŸ—£ï¸ "List all running Python processes"

ğŸ—£ï¸ "Update the project index with my latest changes"

ğŸ—£ï¸ "Explain how the database connection works in this project"
```

### ğŸ’¬ Text Commands

```bash
ğŸ’¬ Write a Python function to validate email addresses
ğŸ’¬ Create a React component for a login form
ğŸ’¬ Debug why my database connection is failing
ğŸ’¬ Refactor this code to use async/await
ğŸ’¬ Generate unit tests for the authentication module
```

---

## ğŸ› ï¸ Tool Arsenal

| Tool | Superpower | Example Command |
|------|------------|-----------------|
| ğŸ”¨ `run_command_with_confirmation` | Execute shell commands safely | "Install numpy using pip" |
| ğŸ“Š `list_processes` | Monitor system resources | "Show memory usage" |
| ğŸš€ `push_to_github` | One-command Git workflow | "Push changes to main" |
| ğŸ” `search_in_files` | Find anything in your codebase | "Find all API endpoints" |
| ğŸ“– `show_python_docs` | Instant documentation | "Show pandas DataFrame docs" |
| ğŸ§  `update_project_index` | RAG-powered code understanding | "Index my React components" |

---

## ğŸ—ï¸ Architecture

```
CodeWhisper/
â”œâ”€â”€ voice_coding_agent/
â”‚   â”œâ”€â”€ audio_test.py          # ğŸ¤ Voice/Text input handler
â”‚   â”œâ”€â”€ code_graph.py           # ğŸ§  LangGraph orchestration
â”‚   â”œâ”€â”€ tools/                  # ğŸ”§ Development superpowers
â”‚   â”‚   â”œâ”€â”€ run_command.py      # Shell execution
â”‚   â”‚   â”œâ”€â”€ list_processes.py   # Process monitoring
â”‚   â”‚   â”œâ”€â”€ push_to_github.py   # Git automation
â”‚   â”‚   â”œâ”€â”€ search_in_files.py  # Code search
â”‚   â”‚   â””â”€â”€ show_python_docs.py # Doc lookup
â”‚   â”œâ”€â”€ rag/                    # ğŸ“š Codebase intelligence
â”‚   â”œâ”€â”€ ai_arena_temp/          # ğŸ¨ Generated code workspace
â”‚   â””â”€â”€ docker-compose.yml      # ğŸ³ MongoDB setup
```

### ğŸ”„ How It Works

```
1. ğŸ¤ Input â†’ Voice/Text captured
2. ğŸ§  Understanding â†’ Gemini interprets intent
3. ğŸ¯ Routing â†’ LangGraph selects appropriate tools
4. âš¡ Execution â†’ Tools run with safety checks
5. ğŸ’¾ Memory â†’ State persisted to MongoDB
6. ğŸ’¬ Response â†’ Natural language feedback
```

---

## ğŸ”§ Advanced Configuration

### Switch AI Models
```python
# In code_graph.py
llm = init_chat_model("google_genai:gemini-2.0-flash")

# Alternatives:
# llm = init_chat_model("openai:gpt-4")
# llm = init_chat_model("anthropic:claude-3-opus")
```

### Customize Conversation Threads
```python
# Start new conversation
config = {"configurable": {"thread_id": "project-alpha"}}

# Resume conversation
config = {"configurable": {"thread_id": "existing-id"}}
```

### Adjust Voice Recognition
```python
recognizer.pause_threshold = 2  # Seconds of silence before processing
recognizer.adjust_for_ambient_noise(source, duration=1)
```

---

## ğŸ“Š Performance & Requirements

| Component | Specification |
|-----------|--------------|
| **RAM** | 4GB minimum, 8GB recommended |
| **Storage** | 500MB for dependencies + codebase |
| **Network** | Required for AI API calls |
| **Microphone** | Any USB or built-in mic (48kHz+ recommended) |
| **OS** | Windows, macOS, Linux (Ubuntu tested) |

---

## ğŸ¤ Contributing

We'd love your help making CodeWhisper even better! 

### How to Contribute

1. ğŸ´ Fork the repository
2. ğŸŒ¿ Create your feature branch: `git checkout -b feature/AmazingFeature`
3. ğŸ’¬ Commit your changes: `git commit -m 'Add AmazingFeature'`
4. ğŸ“¤ Push to the branch: `git push origin feature/AmazingFeature`
5. ğŸ‰ Open a Pull Request

### Development Setup

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dev dependencies
pip install -r requirements-dev.txt

# Run tests
pytest tests/ -v
```

### Ideas for Contributions

- ğŸŒ Add support for more LLMs (Anthropic, Ollama, local models)
- ğŸ¨ Build a web interface
- ğŸ”Œ Create IDE plugins (VS Code, JetBrains)
- ğŸŒ Multi-language support
- ğŸ“ Improve documentation
- ğŸ› Fix bugs and improve error handling

---

## ğŸ› Troubleshooting

<details>
<summary><b>ğŸ¤ Voice Recognition Not Working</b></summary>

- Verify microphone permissions in system settings
- Test microphone: `python -c "import speech_recognition as sr; print(sr.Microphone.list_microphone_names())"`
- Reduce ambient noise
- Install PyAudio properly: `pip install pyaudio`
</details>

<details>
<summary><b>ğŸ”Œ MongoDB Connection Failed</b></summary>

- Check if MongoDB is running: `docker ps`
- Verify connection string in `.env`
- Ensure port 27017 is not blocked by firewall
- Test connection: `mongosh mongodb://localhost:27017`
</details>

<details>
<summary><b>ğŸ¤– AI API Errors</b></summary>

- Verify Google API key is valid and active
- Check API quota at Google Cloud Console
- Ensure billing is enabled
- Test with a simple curl request to verify connectivity
</details>

<details>
<summary><b>âš ï¸ "Command Not Found" Errors</b></summary>

- Ensure you're in the correct directory
- Check `ai_arena_temp/` folder exists
- Verify file permissions
- Try with absolute paths
</details>

---

## ğŸ—ºï¸ Roadmap

### ğŸ¯ Upcoming Features

- [ ] ğŸŒ **Multi-LLM Support**: OpenAI, Anthropic, Ollama, local models
- [ ] ğŸ–¥ï¸ **Web Dashboard**: Beautiful UI for managing conversations
- [ ] ğŸ”Œ **IDE Plugins**: VS Code, PyCharm, Cursor integration
- [ ] ğŸŒ **Multi-Language**: Generate code in any programming language
- [ ] ğŸ¨ **Custom Tool Builder**: Create your own tools via GUI
- [ ] ğŸ‘¥ **Team Features**: Shared conversations and knowledge bases
- [ ] ğŸ“± **Mobile App**: iOS/Android companions
- [ ] ğŸ”Š **Voice Customization**: Custom wake words and voice profiles
- [ ] ğŸ“¦ **Docker One-Click Deploy**: Complete containerized setup
- [ ] ğŸ§ª **Test Generation**: Auto-generate unit tests for any code
- [ ] ğŸ“ˆ **Analytics Dashboard**: Track productivity and usage patterns
- [ ] ğŸ” **Enterprise Features**: SSO, audit logs, role-based access

### ğŸŒŸ Future Vision

CodeWhisper aims to become the **universal voice interface for software development**, supporting all languages, frameworks, and workflows while maintaining simplicity and accessibility.

---

## ğŸ† Showcase

> "CodeWhisper has transformed how I prototype. What used to take hours now takes minutes!" - *Beta Tester*

### Built with CodeWhisper
*Coming soon: Show off what you've built using CodeWhisper!*

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

Free to use, modify, and distribute. Commercial use allowed!

---

## ğŸ™ Acknowledgments

Built with amazing open-source tools:

- ğŸ¦œ [LangGraph](https://github.com/langchain-ai/langgraph) - Agentic AI workflows
- ğŸ§  [Google Gemini](https://deepmind.google/technologies/gemini/) - Powerful language model
- ğŸƒ [MongoDB](https://www.mongodb.com/) - Conversation persistence
- ğŸ™ï¸ [SpeechRecognition](https://github.com/Uberi/speech_recognition) - Voice input processing
- ğŸ’š Open Source Community - For inspiration and support

---

## ğŸ“§ Connect

**Himanshu Dahiya**

- ğŸ™ GitHub: [@Uhimanshu9](https://github.com/Uhimanshu9)
- ğŸ“§ Email: dev.himanshu.ai@gmail.com
- ğŸ”— Project: [CodeWhisper](https://github.com/Uhimanshu9/CodeWhisper)

---

<div align="center">

### â­ Star us on GitHub â€” it motivates us a lot!

**Built with â¤ï¸ for developers who think faster than they type**

[Report Bug](https://github.com/Uhimanshu9/CodeWhisper/issues) Â· [Request Feature](https://github.com/Uhimanshu9/CodeWhisper/issues) Â· [Discussions](https://github.com/Uhimanshu9/CodeWhisper/discussions)

</div>
